% ttpaper.sty uses the next packages:
% geometry, [utf8]inputenc, [T1]fontenc, [english]babel, graphicx, [intlimits]amsmath, amssymb, amsthm, caption, titlesec, url
%
% Defined theorem-like environments:
% definition, theorem, lemma, remark, example, corollary, proof
%
% You can define new theorem-like environment in the following way (see amsthm.sty):
% \newtheorem{prob}[theorem]{Problem}

\documentclass{article}
\usepackage{ttpaper}
\newtheorem{prob}[theorem]{Problem}

\title{Concurrent Object Construction in Modern Object-oriented Programming
Languages\thanks{This study/research was supported by a special contract No. 18370-8/2013/TUDPOL with the Ministry of Human Recources.}}
\author{Viktor M\'ajer\inst1, Norbert Pataki\inst2}
\institute{\inst1EPAM System European Headquarters, Budapest\\\url{Viktor_Majer@epam.com}\\
           \inst2Dept. of Programming Languages and Compilers, \\ 
Fac. of Informatics, E\"otv\"os Lor\'and University, Budapest\\\url{patakino@elte.hu}}


\begin{document}
\maketitle

\begin{abstract}
Nowadays concurrency is a key issue in modern object-oriented programming
languages. Billions of objects and object graphs are created at runtime,
thus parallelization of object construction may result in significant
speed-up in applications.

The C++ programming language uses value semantics as basis of
object-orientation. Objects can be used as values and C++ offers copy
constructors automatically that copy all members of a class. This operation
seems to be ideal for parallelization because independent sources need to be
copied to independent targets: without locks, without synchronization problems.

In this paper we present scenarios where parallelization seems to
be valuable. These scenarios belong to object constructions which is fundamental. 
We present our approach and tool that makes the copy constructors concurrent.
This tool is based on the Clang architecture.

%Text of the abstract.
\keywords C++, concurrency, constructors
\AMSclassificationnumber 68N19 Other programming techniques
\end{abstract}

\section{Introduction}

Nowadays hardware supports parallel computation. Performance-oriented applications are using
manycore processors. The multicore processors are available in smartphones, too. The GPGPU
aims execution of general purpose code on the graphic processor. FPGA (Field-programmable
gate  arrays) architectures can also be bought at fair price.

Operating systems and virtualization techniques follow the progress of hardware correctly. 
They can take advantage of parallel behaviour \cite{barham:virtualization}. On the other
hand, the recently widely-used programming languages do not support concurrent programming
adequately \cite{lupin:highlevel}. Typically, the object-oriented languages are far from
ideal approach of parallel execution \cite{tripathi:sina}. These languages support
thread-based programming with a base type of thread \cite{oaks:thread}. The programmers have
to create a subtype and deal with synchronization, communication and locks \cite{hughes:thread}.
However, thread is low level construct from the view of the processor's architecture. Hard to
write efficient, scalable and maintainable code for multi- and manycore  architectures with
this approach.

The C++ programming language is famous for taking advantage of the hardware capabilities. It
supports thread-based programmming since the C++11 standard \cite{batty:math}. Some elemental
types (like \texttt{thread}, \texttt{future}, \texttt{mutex}) can be used but these constructs
are not so high-level to deal with current hardware architectures \cite{stroustrup:cpp}.
Unfortunately, they also do not support scalability, thus more convenience tools are
required \cite{lupin:fastflow,lupin:multicore,lupin:stl}.

C++ uses value semantics as basis of object-orientation. Objects can be used as values and C++
offers copy constructors automatically that copy all members of a class. This operation runs
sequentially, but it is ideal for parallelization because independent sources need to be copied
to independent targets: without locks, without synchronization problems.

In this paper we argue for a new kind of copy constructor execution. Because programmers are eager
for easy-to-use and efficient parallel execution, we define copy constructors to run faster than
the standard one. We use the Clang architecture for creating custom copy constructors \cite{lattner:clang}.

This paper is organized as follows. In the section \ref{motivation} we argue for a new approach
for making copy constructors concurrent in C++. After, we present our tool and architecture that
makes the execution of constructors parallel in section \ref{architecture}. The evaluation of
measurements and the approach is detailed in section \ref{measurements}. Finally, this paper
concludes in section \ref{conc}.

\section{Motivation}
\label{motivation}

The object-oriented approach of C++ is based on the value semantics. Let us consider that we
have a class that represents complex numbers:

\begin{verbatim}
class complex
{
private:
  double re, im;
public:
  // ...
};
\end{verbatim}

The objects that we create are values, not just links. The constructed complex numbers are
created on the runtime stack, just like an integer. We can call the copy constructor to
create copies from a complex number, even if this constructor is invisible on the public
interface. The automatically created copy constructor copies all the members of the class,
that is fine in this case:

\begin{verbatim}
void f()
{
  complex a( 3.2, 5.6 );
  complex b = a;
  // ...
}
\end{verbatim}

Let us consider a more complicated class that represents students. A student has surname,
first name, mother's name and grades grouped by subjects:

\begin{verbatim}
class student
{
private:
  std::string surname, first_name, mother_name;
  std::map<std::string, std::vector<int> > grades;
public:
  // ...
};
\end{verbatim}

There is a copy constructor that copies all elements sequentially. However, this operation
can be faster if we take advantage of threads. The automatic copying process should be done
in a multithreaded way to achieve speed-up. The question is which members are copied on
the same thread. We aggregate some tuples that are copied concurrently. Every thread copies
one tuple. However, copying every member on a different thread is not reasonable. In this
paper we present our approach to make the copy constructor concurrent.

\section{Our approach}
\label{approach}
As we said earlier, the heart of our approach is to copying the data members of an object from a given class in different execution threads. To achieve this, we arrange the data members into tuples, which tuples are disjunct groups of the fields to be copied. The key question is how to form these groups to provide more efficient copy-constructor than its single-threaded version. 

To answer this question we concluded performance tests to see which type of fields and data structures are worth to be copied on a separate thread. These tests showed that in case of primitive types the performance gain is negligible, furthermore it is rather a performance overhead.

However these tests also revealed, that
\begin{itemize}
 \item if a type's copy-constructor is expensive\footnote{in this paper under expensive we always mean expensive in time} enough, and
 \item some sort of collection containing objects of this type is stored as a field
\end{itemize}

then simultaneous copy of these fields can represent a real performance benefit. Based on these experiences our grouping approach for a given class is:
\begin{enumerate}
 \item Form a group from all of the fields having primitive type, or declared as a pointer
 \item Create a group from fields having user declared type (extending CostlyObject)
 \item Form a group from STL containers containing costly objects
\end{enumerate}

% rewrote this part
// ******** rewrite *********

Note, that there is still considerable uncertainty in this grouping mechanism. We refer to costly objects, however it is not trivial to programmatically determine the costs of copying an object. It is hard, yet possible to create heuristics based only on the implementation of a type, but this is beyond the scope of this paper.

Nevertheless this problem can easily addressed with manual contribution from the side of the user. We provided a method with that the implementor of a given type can indicate that its copying is presumably expensive. This indicator should be used on types recursively, since every type that has at least one field which type or value type is marked as expensive, is expensive itself. Every type marked as expensive is then candidate for having a concurrent copy constructor. 

//**************************
% until this point

Having these said, all we have to do is to:
\begin{enumerate}
 \item look up every class in the compiling units those do not have a user-defined copy constructor and marked as expensive type
 \item generate copy constructor for each of these class by creating separate copy-groups according to the mentioned grouping rules, let these these groups execute on separate threads and finally join these threads
\end{enumerate}

\section{Our architecture}
\label{architecture}

To implement the outlined approach we needed a compiler architecture that is flexible and extensible enough to allow this kind of static analysis and source code transformation. We chose the Clang front-end built on the LLVM compiler architecture for this purpose due to its suitable characteristics \cite{lattner:clang}. The following is an overview of our tool implementation using Clang.

When writing a Clang-based tool, the common entry point is the \texttt{FrontendAction}. This is an interface that allows execution of user specific actions as part of the compilation. To run tools over the AST (Abstract Syntax Tree) Clang provides the convenience interface \texttt{ASTFrontendAction}, which takes care of executing the action. The only part left is to implement the \texttt{CreateASTConsumer} method that returns an \texttt{ASTConsumer} per translation unit.

\begin{verbatim}
class FindExpensiveClassAction : public clang::ASTFrontendAction {
public:
  virtual clang::ASTConsumer *CreateASTConsumer(
  	clang::CompilerInstance &Compiler, llvm::StringRef InFile) {
    return new FindExpensiveClassConsumer(&Compiler);
  }
};
\end{verbatim}

Now we have to define \texttt{FindExpensiveClassConsumer}. \texttt{ASTConsumer} is an interface used to write generic actions on an AST, regardless of how the AST was produced. \texttt{ASTConsumer} provides many different entry points, but for our use case the only one needed is \texttt{HandleTranslationUnit}, which is called with the \texttt{ASTContext} for the translation unit.

\begin{verbatim}
class FindExpensiveClassConsumer : public clang::ASTConsumer {
public:
  explicit FindExpensiveClassConsumer(CompilerInstance *Compiler)
    : Visitor(Compiler) {}

    virtual void HandleTranslationUnit(clang::ASTContext &Context) {
        Visitor.TraverseDecl(Context.getTranslationUnitDecl());
    }
private:
  FindExpensiveClassVisitor Visitor;
};
\end{verbatim}

To extract the relevant information from the AST, we implement Clang's \texttt{RecursiveASTVisitor} - it is called \texttt{FindExpensiveClassVisitor} in our tool.
The \texttt{RecursiveASTVisitor} provides hooks of the form \texttt{bool VisitNodeType(NodeType *)} for most AST nodes. In our case we only need to implement the methods for the relevant node types, which is only \texttt{CXXRecordDecl} that represents a C++ struct/union/class.

\begin{verbatim}
class FindExpensiveClassVisitor
  : public RecursiveASTVisitor<FindExpensiveClassVisitor> {
public:
  //...
  bool VisitCXXRecordDecl(CXXRecordDecl *Decl) {
  	const bool hasCopyCtr = Decl->hasUserDeclaredCopyConstructor();   
    if (!hasCopyCtr && Declaration->isCompleteDefinition()) {
        injectCCopyConstructor(Decl);
    }
    return true;
  }
  //...  
};
\end{verbatim}



\section{Measurements}
\label{measurements}

\section{Conclusion}
\label{conc}

\begin{thebibliography}{10}

\bibitem{barham:virtualization}
Barham, P., Dragovic, B., Fraser, K., Hand, S., Harris, T., Ho, A., Neugebauer, R., Pratt, I,
Warfield, A.: \emph{Xen and the Art of Virtualization}, In Proc. of the 19th ACM SOSP, 2003,
pp. 164--173.

\bibitem{batty:math}
Batty, M., Owens, S., Sarkar, S., Sewell, P., Weber, T.: \emph{Mathematizing C++ concurrency},
in Proc. of the 38th annual ACM SIGPLAN-SIGACT Symposium on Principles of programming languages,
(POPL'11), 2011, pp. 55-66

\bibitem{hughes:thread}
Hughes, C., Hughes, T.: ``Object-Oriented Multithreading Using C++'', Wiley (1997)

\bibitem{lattner:clang}
Lattner, C.: \emph{{LLVM} and {C}lang: Next Generation Compiler Technology}, The BSD Conference,
2008.

\bibitem{oaks:thread}
Oaks, S., Wong, H.: ``Java Threads'' (Third Edition), O'Reilly (2004)

\bibitem{stroustrup:cpp}
Stroustrup, B.: ``The C++ Programming Language'' (Fourth Edition), Addison-Wesley (2013)

\bibitem{lupin:fastflow}
Sz\H{u}gyi, Z., Pataki N.: \emph{Generative Version of the FastFlow Multicore Library},
Electronic Notes in Theoret. Comput. Sci., \textbf{279(3)}, pp. 73--84.

\bibitem{lupin:multicore}
Sz\H{u}gyi, Z., T\"or\"ok, M., Pataki N., Kozsik, T.: \emph{Multicore C++ Standard Template Library
with C++0x}, in Proc. of International Conference on Numerical Analysis and Applied
Mathematics (ICNAAM 2011), American Institute of Physics, \textbf{1389}, pp. 857--860.

\bibitem{lupin:stl}
Sz\H{u}gyi, Z., T\"or\"ok, M., Pataki N.: \emph{Towards a multicore C++ Standard Template Library},
in Proc. of Workshop on Generative Programming 2011 (WGT 2011), 2011, pp. 38--48.

\bibitem{lupin:highlevel}
Sz\H{u}gyi, Z., T\"or\"ok, M., Pataki N., Kozsik, T.: \emph{High-level Multicore Programming with C++11},
Computer Science and Information Systems, \textbf{9(3)}, pp. 1187--1202.

\bibitem{tripathi:sina}
Tripathi, A., Berge, E., Aksit, M.: \emph{An implementation of object-oriented concurrent
programmming language SINA}, Software Practice and Experience, \textbf{19(3)}, pp. 235--256.

\bibitem{voufo:clang}
Voufo, L., Zalewski, M., Lumsdaine, A.: \emph{ConceptClang: an implementation of C++ concepts in Clang},
in Proc. of the seventh ACM SIGPLAN workshop on Generic programming (WGP '11), 2011, pp. 71--82.

\end{thebibliography}

\end{document}
